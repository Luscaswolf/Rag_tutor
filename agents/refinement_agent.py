from langchain_community.chat_models import ChatOpenAI


def refine_response(raw_answer, question):
    llm = ChatOpenAI(model_name="gpt-3.5-turbo-0125",
                     temperature=0.3)  # ğŸ”º usa o mesmo modelo barato
    prompt = f"""
VocÃª Ã© um assistente responsÃ¡vel por revisar respostas geradas por um sistema de recuperaÃ§Ã£o de informaÃ§Ã£o.
Pergunta: {question}
Resposta inicial: {raw_answer}
Revise ou melhore a resposta se necessÃ¡rio, mantendo-a clara e correta.
"""
    return llm.invoke(prompt).content  # ğŸ”º Extrai apenas o conteÃºdo puro
